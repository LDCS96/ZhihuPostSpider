# ZhihuPostSpider
原理
-------------------
##### 知乎的文章页面的网址（或统一资源定位符，url）都是“https://zhuanlan/zhihu.com/p/XXX” 这种形式。不同文章的“XXX”编号不同。不过知乎这网站有个略坑之处，就是文章不连号。有些号码对应的url是没有内容的，如果访问会返回404错误。比如“https://zhuanlan/zhihu.com/p/1” 就是个空网址（404）。所有文章的编号，只有他乎的服务器自己清楚。对于我等凡夫俗子，动用大脑资源去记忆一大批8位数没排列规则的文章编号，既不人道，也无必要。所以，就只能辛苦一下计算机同志，挨个遍历过去了。遇到404程序会抛出(urllib.error.)HTTPError错误，用try-except语句捕捉。
使用
-------------------
##### 用fiddler抓个包，把请求头里的user-agent复制到代码里header字典的第一行“user-agent”后面的XXX里，再登录一下知乎，抓一下GET请求https://www.zhihu.com/ 的包，把里面的cookie复制到“cookie”后面的XXX里。前者的目的是弱弱地假装一下自己不是爬虫；需要执行后者则是因为他乎这个大爷网站不知从哪年哪月的哪位产品经理开始，规定要浏览知乎必须得登录帐号（没有还得注册一个）。所以没有cookie，我等是半点数据也休想拿到。
##### 另外，想象一下你现在就是知乎服务器。某天你泡好一杯茶，坐在屏幕前观看万千屁民韭菜上你家网站打发时间。突然有个“用户”，一秒钟访问了某个页面十几次，请求头还简陋得一匹，你会怎么想？神仙也没这手速啊，爬虫软件实锤了。如果你碰巧遇到了个扛靶子安全员，你的IP很可能就杯具了。解决办法很简单，找个高匿代理（比如西刺免费代理网站）。ProxyHandler类的构造函数的参数是一个字典，键是代理的类型，比如HTTP，HTTPS或SOCKS4/5；值是IP地址以及冒号加端口号，填入就行了。
